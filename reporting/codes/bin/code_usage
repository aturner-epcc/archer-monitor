#!/usr/bin/env python
#
#===============================================================
# code_usage
#
# Analyse code usage from logs
#===============================================================
#
#===============================================================
# v0.2 - Read from separate log files (one for each day)
# v0.1 - Initial version
#===============================================================
#
#----------------------------------------------------------------------
# Copyright 2014 EPCC, The University of Edinburgh
#
# This file is part of archer-monitoring.
#
# archer-monitoring is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# archer-monitoring is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with archer-monitoring.  If not, see <http://www.gnu.org/licenses/>.
#----------------------------------------------------------------------
#
"""Get code usage statistics from specified log file.

OPTIONS

-h,--help                Show this help.
"""
__author__ = 'Andrew Turner, EPCC, The University of Edinburgh'
__version__ = '0.2'

# Import the required modules
from code_def import CodeDef
from timelineplot import get_filelist
from datetime import datetime, timedelta
import err_handle as error
import sys
import os
import fnmatch
import getopt
import subprocess
import ConfigParser
import grp
import re
import time

def main(argv):

    #=======================================================
    # Print out the banner
    #=======================================================
    sys.stderr.write("===========================================================================\n")
    sys.stderr.write("code_usage " + __version__ + "\n")
    sys.stderr.write("---------------------------------------------------------------------------\n")
    sys.stderr.write("Copyright 2012  EPCC, The University of Edinburgh \n")
    sys.stderr.write("This program comes with ABSOLUTELY NO WARRANTY; for details type `code_usage -i'.\n")
    sys.stderr.write("This is free software, and you are welcome to redistribute it\n")
    sys.stderr.write("under certain conditions; type `code_usage -i' for details.\n")
    sys.stderr.write("===========================================================================\n")

    #=======================================================
    # Global configuration section
    #=======================================================
    rootDir = os.environ['ARCHER_MON_BASEDIR']
    sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]
    thresh = 0.005

    #=======================================================
    # Read any code definitions
    #=======================================================
    codeConfigDir = rootDir + '/reporting/codes/descriptions'
    codes = []
    nCode = 0
    # We also need to create a dictionary of resources here
    codeDict = {}
    for file in os.listdir(codeConfigDir):
        if fnmatch.fnmatch(file, '*.code'):
            nCode += 1
            code = CodeDef()   
            code.readConfig(codeConfigDir + '/' + file)
            codes.append(code)
            codeDict[code.name] = nCode - 1

    # Here we loop over all defined codes zeroing the appropriate variables and dicts
    totjobs = 0
    totnh = 0
    totusers = 0
    tot_nh_bysize = {}
    tot_jobs_bysize = {}
    matchedjobs = {}
    users = ''
    code_regexp = {}
    code_users = {}
    code_num_users = {}
    code_nh = {}
    code_nh_bysize = {}
    code_jobs = {}
    code_jobs_bysize = {}
    other_nh = 0
    other_users = ""
    other_num_users = 0
    other_nh_bysize = {}
    other_jobs = 0
    other_jobs_bysize = {}
    other_codes = {}
    for size in sizes:
       tot_nh_bysize[size] = 0
       tot_jobs_bysize[size] = 0
       other_nh_bysize[size] = 0
       other_jobs_bysize[size] = 0
    for code in codes:
       name = code.name
       code_regexp[name] = code.regexp
       code_nh[name] = 0
       code_jobs[name] = 0
       code_users[name] = ''
       code_num_users[name] = 0
       for size in sizes:
          # This is funky Python syntax for defining a 2D dict
          code_nh_bysize[name] = code_nh_bysize.get(name, {})
          code_nh_bysize[name][size] = 0
          code_jobs_bysize[name] = code_jobs_bysize.get(name, {})
          code_jobs_bysize[name][size] = 0
       

    #=======================================================
    # Command line options
    #=======================================================
    # Read the command-line options
    try:
        opts, args = getopt.getopt(argv, "n:N:d:A:t:o:r:b:q:j:c:plshi", \
                      ["tasks=", "tasks-per-node=", "threads=", "account=", \
                      "job-time=", "output-file=", "resource=", "batch=", "queue=", \
                      "job-name=", "code=", "force-parallel", "list", "submit", \
                      "help", "info"])
    except getopt.GetoptError:
        error.handleError("Could not parse command line options\n")

    # Parse the command-line options
    for opt, arg in opts:
        if opt in ("-h", "--help"):
            printHelp(rootDir)
            exit(0)


    # Get the start and end times
    starttime = 0
    endtime = time.mktime(time.gmtime())

    now = datetime.today()

    startfile = datetime.utcfromtimestamp(0)
    startdate = datetime.utcfromtimestamp(0)

    # Read the name of the logfile directory and open it
    indir = argv[0]
    sys.stdout.write("Analysing data in: {0}\n".format(indir))
    files = get_filelist(indir, 'apstat')


    for file in files:
     filename = os.path.basename(file)
     print filename
     filedate = filename.split('.')[0]
     fdate = datetime.strptime(filedate, "%Y-%m-%d")
     if fdate >= startfile:
         # This is where we will read and process data
         logFile = open(file, "r")

         # Initialise variables
         intimerange = False
         # Loop over lines in the file reading them
         for line in logFile:

            if re.match("__START", line) is not None:
               timeline = line.rstrip()
               tokens = timeline.split()
               thistime = int(time.mktime(time.strptime(tokens[1], "%Y-%m-%d")))
               # If we are past the end time then finish the loop
               if thistime > endtime:
                  sys.stdout.write("Finished at: {0}".format(timeline))
                  break
               elif thistime >= starttime:
                  intimerange = True
                  continue
            # End of if start block match

            # If we are in the time range then accumulate data
            if intimerange:
               
               # Skip the end indicator
               if re.match("__END", line) is not None:
                  continue


               # Extract the useful information from the log
               line = line.rstrip()
               tokens = line.split()

               if len(tokens) < 8:
                   continue
               jobid = tokens[0]
               user = tokens[2]
               nodes = tokens[4]
               exename = tokens[7]

               # Add this number of hours to total
               totnh += int(nodes)

               # Check we have not already seen this job
               countjob = True
               if jobid in matchedjobs:
                  countjob = False
               else:
                  totjobs += 1
                  matchedjobs[jobid] = True

               # Check if we have already seen this user
               if user not in users:
                  users = "{0} {1}".format(users, user)
                  totusers += 1

               # Loop over codes, storing this job
               matched = False
               for code in codes:
                  name = code.name
                  if re.search(code_regexp[name], exename):
                     matched = True
                     code_nh[name] += int(nodes)
                     if countjob: code_jobs[name] += 1
                     if user not in code_users[name]:
                        code_users[name] = "{0} {1}".format(code_users[name], user)
                        code_num_users[name] += 1
                     for size in sizes:
                        if int(nodes) <= size:
                           code_nh_bysize[name][size] += int(nodes)
                           tot_nh_bysize[size] += int(nodes)
                           if countjob:
                              code_jobs_bysize[name][size] += 1
                              tot_jobs_bysize[size] += 1
                           break
               # End of loop over codes

               # Store if not matched to defined code
               if not matched:
                  other_nh += int(nodes)
                  if exename in other_codes:
                     other_codes[exename] += int(nodes)
                  else:
                     other_codes[exename] = int(nodes)
                  if countjob: other_jobs += 1
                  if user not in other_users:
                     other_users = "{0} {1}".format(other_users, user)
                     other_num_users += 1
                  for size in sizes:
                     if int(nodes) <= size:
                        other_nh_bysize[size] += int(nodes)
                        tot_nh_bysize[size] += int(nodes)
                        if countjob:
                           other_jobs_bysize[size] += 1
                           tot_jobs_bysize[size] += 1
                        break
 
            # End of if intimerange

         # End of loop over logfile lines
         
         # Close the logfile
         logFile.close()
    # End of loop over logfiles

    totnh = 0
    totjobs = 0
    for name in sorted(code_nh, key=code_nh.get, reverse=True):
        totnh = totnh + code_nh[name]
        totjobs = totjobs + code_jobs[name]
    totnh = totnh + other_nh
    totjobs = totjobs + other_jobs

    # Loop over codes printing usage
    sys.stdout.write("\n\nTotal code usage (ordered by node hours)\n")
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}{5:>10s}\n".format("Code", "Node Hours", "% Time", "Jobs", "% Jobs", "Users"))
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}{5:>10s}\n".format("====", "==========", "======", "====", "======", "====="))
    for name in sorted(code_nh, key=code_nh.get, reverse=True):
       nhfrac = 100 * float(code_nh[name])/float(totnh)
       jobfrac = 100 * float(code_jobs[name])/float(totjobs)
       sys.stdout.write("{0:>20s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}{5:10d}\n".format(name, code_nh[name], nhfrac, code_jobs[name], jobfrac, code_num_users[name]))
    nhfrac = 100 * float(other_nh)/float(totnh)
    jobfrac = 100 * float(other_jobs)/float(totjobs)
    sys.stdout.write("{0:>20s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}{5:10d}\n".format("Unknown", other_nh, nhfrac, other_jobs, jobfrac, other_num_users))
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}{5:>10s}\n".format("----", "----------", "------", "----", "------", "-----"))
    nhfrac = 100 * float(totnh)/float(totnh)
    jobfrac = 100 * float(totjobs)/float(totjobs)
    sys.stdout.write("{0:>20s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}{5:10d}\n".format("Total", totnh, nhfrac, totjobs, jobfrac, totusers))
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}{5:>10s}\n".format("====", "==========", "======", "====", "======", "====="))

    # Node hours by job size
    sys.stdout.write("\n\nNode hours by job size\n")
    head = "{0:>20s}".format("Code")
    lines = "{0:>20s}".format("====")
    for size in sizes:
       head = head + "{0:>10d}".format(size)
       lines = lines + "{0:>10s}".format("=====")
    sys.stdout.write(head + "\n" + lines + "\n")
    for name in sorted(code_nh, key=code_nh.get, reverse=True):
       sys.stdout.write("{0:>20s}".format(name))
       for size in sizes:
          sys.stdout.write("{0:10d}".format(code_nh_bysize[name][size]))
       sys.stdout.write("\n")
    sys.stdout.write("{0:>20s}".format("Unknown"))
    for size in sizes:
       sys.stdout.write("{0:>10d}".format(other_nh_bysize[size]))
    sys.stdout.write("\n")
    lines = "{0:>20s}".format("----")
    for size in sizes:
       lines = lines + "{0:>10s}".format("-----")
    sys.stdout.write(lines + "\n")
    sys.stdout.write("{0:>20s}".format("Total"))
    for size in sizes:
       sys.stdout.write("{0:>10d}".format(tot_nh_bysize[size]))
    sys.stdout.write("\n")
    lines = "{0:>20s}".format("====")
    for size in sizes:
       lines = lines + "{0:>10s}".format("====")
    sys.stdout.write(lines + "\n")

    # Jobs by job size
    sys.stdout.write("\n\nNumber of jobs by job size\n")
    head = "{0:>20s}".format("Code")
    lines = "{0:>20s}".format("====")
    for size in sizes:
       head = head + "{0:>10d}".format(size)
       lines = lines + "{0:>10s}".format("=====")
    sys.stdout.write(head + "\n" + lines + "\n")
    for name in sorted(code_nh, key=code_nh.get, reverse=True):
       sys.stdout.write("{0:>20s}".format(name))
       for size in sizes:
          sys.stdout.write("{0:10d}".format(code_jobs_bysize[name][size]))
       sys.stdout.write("\n")
    sys.stdout.write("{0:>20s}".format("Unknown"))
    for size in sizes:
       sys.stdout.write("{0:>10d}".format(other_jobs_bysize[size]))
    sys.stdout.write("\n")
    lines = "{0:>20s}".format("----")
    for size in sizes:
       lines = lines + "{0:>10s}".format("-----")
    sys.stdout.write(lines + "\n")
    sys.stdout.write("{0:>20s}".format("Total"))
    for size in sizes:
       sys.stdout.write("{0:>10d}".format(tot_jobs_bysize[size]))
    sys.stdout.write("\n")
    lines = "{0:>20s}".format("====")
    for size in sizes:
       lines = lines + "{0:>10s}".format("====")
    sys.stdout.write(lines + "\n")

    # Aggregate results on code metadata
    lang_nh = {}
    lang_jobs = {}
    for code in codes:
       name = code.name
       lang = code.pri_lang
       if lang in lang_nh:
          lang_nh[lang] += code_nh[name]
          lang_jobs[lang] += code_jobs[name]
       else:
          lang_nh[lang] = code_nh[name]
          lang_jobs[lang] = code_jobs[name]
    # Loop over codes printing usage
    sys.stdout.write("\n\nTotal language usage (ordered by node hours)\n")
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("Code", "Node Hours", "% Time", "Jobs", "% Jobs"))
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("====", "==========", "======", "====", "======"))
    for lang in sorted(lang_nh, key=lang_nh.get, reverse=True):
       nhfrac = 100 * float(lang_nh[lang])/float(totnh)
       jobfrac = 100 * float(lang_jobs[lang])/float(totjobs)
       sys.stdout.write("{0:>20s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format(lang, lang_nh[lang], nhfrac, lang_jobs[lang], jobfrac))
    nhfrac = 100 * float(other_nh)/float(totnh)
    jobfrac = 100 * float(other_jobs)/float(totjobs)
    sys.stdout.write("{0:>20s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format("Unknown", other_nh, nhfrac, other_jobs, jobfrac))
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("----", "----------", "------", "----", "------"))
    nhfrac = 100 * float(totnh)/float(totnh)
    jobfrac = 100 * float(totjobs)/float(totjobs)
    sys.stdout.write("{0:>20s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format("Total", totnh, nhfrac, totjobs, jobfrac))
    sys.stdout.write("{0:>20s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("====", "==========", "======", "====", "======"))

    # Aggregate results on type metadata
    meta_nh = {}
    meta_jobs = {}
    for code in codes:
       name = code.name
       meta = code.type
       if meta in meta_nh:
          meta_nh[meta] += code_nh[name]
          meta_jobs[meta] += code_jobs[name]
       else:
          meta_nh[meta] = code_nh[name]
          meta_jobs[meta] = code_jobs[name]
    # Loop over codes printing usage
    sys.stdout.write("\n\nTotal type usage (ordered by node hours)\n")
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("Code", "Node Hours", "% Time", "Jobs", "% Jobs"))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("====", "==========", "======", "====", "======"))
    for meta in sorted(meta_nh, key=meta_nh.get, reverse=True):
       nhfrac = 100 * float(meta_nh[meta])/float(totnh)
       jobfrac = 100 * float(meta_jobs[meta])/float(totjobs)
       sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format(meta, meta_nh[meta], nhfrac, meta_jobs[meta], jobfrac))
    nhfrac = 100 * float(other_nh)/float(totnh)
    jobfrac = 100 * float(other_jobs)/float(totjobs)
    sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format("Unknown", other_nh, nhfrac, other_jobs, jobfrac))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("----", "----------", "------", "----", "------"))
    nhfrac = 100 * float(totnh)/float(totnh)
    jobfrac = 100 * float(totjobs)/float(totjobs)
    sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format("Total", totnh, nhfrac, totjobs, jobfrac))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("====", "==========", "======", "====", "======"))

    # Aggregate results on type metadata
    meta_nh = {}
    meta_jobs = {}
    for code in codes:
       name = code.name
       meta = code.area
       if meta in meta_nh:
          meta_nh[meta] += code_nh[name]
          meta_jobs[meta] += code_jobs[name]
       else:
          meta_nh[meta] = code_nh[name]
          meta_jobs[meta] = code_jobs[name]
    # Loop over codes printing usage
    sys.stdout.write("\n\nTotal area usage (ordered by node hours)\n")
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("Code", "Node Hours", "% Time", "Jobs", "% Jobs"))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("====", "==========", "======", "====", "======"))
    for meta in sorted(meta_nh, key=meta_nh.get, reverse=True):
       nhfrac = 100 * float(meta_nh[meta])/float(totnh)
       jobfrac = 100 * float(meta_jobs[meta])/float(totjobs)
       sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format(meta, meta_nh[meta], nhfrac, meta_jobs[meta], jobfrac))
    nhfrac = 100 * float(other_nh)/float(totnh)
    jobfrac = 100 * float(other_jobs)/float(totjobs)
    sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format("Unknown", other_nh, nhfrac, other_jobs, jobfrac))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("----", "----------", "------", "----", "------"))
    nhfrac = 100 * float(totnh)/float(totnh)
    jobfrac = 100 * float(totjobs)/float(totjobs)
    sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}{3:10d}{4:10.2f}\n".format("Total", totnh, nhfrac, totjobs, jobfrac))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}{3:>10s}{4:>10s}\n".format("====", "==========", "======", "====", "======"))
    # Print out any other executables with usage over 1%
    percent = thresh * float(totnh)
    sys.stdout.write("\n\nUndefined executables with usage greater than {0:5.2f}% of total node hours:\n".format(100*thresh))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}\n".format("Code", "Node Hours", "% Time"))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}\n".format("====", "==========", "======"))
    other_tot = 0
    for name in sorted(other_codes, key=other_codes.get, reverse=True):
       if other_codes[name] > percent:
          nhfrac = 100 * float(other_codes[name])/float(totnh)
          other_tot += int(other_codes[name])
          sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}\n".format(name, other_codes[name], nhfrac))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}\n".format("----", "----------", "------"))
    nhfrac = 100 * float(other_tot)/float(totnh)
    sys.stdout.write("{0:>30s}{1:15d}{2:10.2f}\n".format("Total", other_tot, nhfrac))
    sys.stdout.write("{0:>30s}{1:>15s}{2:>10s}\n".format("====", "==========", "======"))


    # Finish nicely
    exit(0)

def printHelp(rootDir):
    """Print help for the tool.
           
           Arguments:
              str rootDir - The root install directory of the tool.
        """
    subprocess.call(["pydoc", rootDir + "/reporting/codes/bin/code_usage"])

if __name__ == "__main__":
    main(sys.argv[1:])
